# LLM provider: openai_compat | ollama | none
LLM_PROVIDER=none

# OpenAI-compatible API settings (Groq recommended)
LLM_API_KEY=
LLM_BASE_URL=https://api.groq.com/openai/v1
LLM_MODEL=llama-3.3-70b-versatile
LLM_FALLBACK_MODEL=llama-3.1-8b-instant

# Ollama settings (free local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct

# Retrieval settings (later, when we add vector DB)
EMBEDDING_MODEL=intfloat/multilingual-e5-large
CHROMA_DIR=./data/index
CHROMA_COLLECTION=infohub_docs

# Optional cookie for authenticated InfoHub requests (later)
INFOHUB_COOKIE=
